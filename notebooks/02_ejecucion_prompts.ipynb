{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.prompting_utils import aplicar_prompt_a_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4f7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGAMOS LOS DATOS\n",
    "df = pd.read_csv(\"../data/ejemplos_tarea.csv\")\n",
    "\n",
    "print(\"Primeras filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c76bda",
   "metadata": {},
   "source": [
    "Defino la plantilla de los prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt 1: INSTRUCCIÓN DIRECTA SIN EJEMPLOS\n",
    "prompt_1 = \"\"\"Clasifica el sentimiento del siguiente texto como positivo, negativo o neutro:\n",
    "\n",
    "Texto: {}\"\"\"\n",
    "\n",
    "# Prompt 2: CON EJEMPLOS (in-context learning)\n",
    "prompt_2 = \"\"\"Clasifica el sentimiento del siguiente texto:\n",
    "\n",
    "Ejemplos:\n",
    "Texto: Me encantó la película. → Sentimiento: positivo\n",
    "Texto: No me gustó. → Sentimiento: negativo\n",
    "Texto: Estuvo bien. → Sentimiento: neutro\n",
    "\n",
    "Texto: {} → Sentimiento:\"\"\"\n",
    "\n",
    "# Prompt 3: INSTRUCCIONES + EJEMPLOS + ROL DEL MODELO\n",
    "prompt_3 = \"\"\"Eres un modelo de lenguaje experto en análisis de sentimientos. \n",
    "Clasifica cada texto como 'positivo', 'negativo' o 'neutro'.\n",
    "\n",
    "Ejemplos:\n",
    "Texto: Me encanta esto. → positivo\n",
    "Texto: Lo odio. → negativo\n",
    "Texto: Es aceptable. → neutro\n",
    "\n",
    "Texto: {} →\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b9f79",
   "metadata": {},
   "source": [
    "SE ejecutan los 3 prompts sobre el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRAER SOLO LA COLUMNA DE TEXTO\n",
    "textos = df['texto'].tolist()\n",
    "\n",
    "#APLICAR CADA PROMPT A TODOS LOS TEXTOS\n",
    "print(\"Ejecutando Prompt 1...\")\n",
    "df['respuesta_p1'] = aplicar_prompt_a_lista(textos, prompt_1)\n",
    "\n",
    "print(\"Ejecutando Prompt 2...\")\n",
    "df['respuesta_p2'] = aplicar_prompt_a_lista(textos, prompt_2)\n",
    "\n",
    "print(\"Ejecutando Prompt 3...\")\n",
    "df['respuesta_p3'] = aplicar_prompt_a_lista(textos, prompt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7d56a",
   "metadata": {},
   "source": [
    "Se crea la carpeta results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "#SE GUARDA LOS RESULTADOS COMPLETOS\n",
    "df.to_csv(\"../results/respuestas_prompts.csv\", index=False)\n",
    "print(\"Respuestas guardadas en '../results/respuestas_prompts.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8659aae",
   "metadata": {},
   "source": [
    "Vista rápida de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f389771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['texto', 'label', 'respuesta_p1', 'respuesta_p2', 'respuesta_p3']].head(10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
